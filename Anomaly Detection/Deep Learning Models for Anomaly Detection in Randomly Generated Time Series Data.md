Notes: 
- Re-phrase all what follows
- Collect Research Paper Resources on Desktop and Drive + Append to "Resources"
- Comment on Graphs
  - CNN-AE's good learning ability and good train data reconstruction capability  
  - Transformer + LSTM-AE's inability to reconstruct sequences (in additon to average-like "line", which did well eventually!)
- Brief background about every model used
- Comparison between models Section + Comment on each of the model's advantages and disadvantages
- Comment on the general strong performance of the models
- Upcoming Plans 
  - What models are next?
  - Testing models on well-known published time series datasets



Subtitles:
- Abstract
Time series anomalies can offer information relevant to critical situations facing various fields, from astronomy and finance to the IT and medical domains. However, detecting anomalies in time series data is particularly challenging due to the vague definition of anomalies and said dataâ€™s frequent lack of labels and highly complex temporal correlations. In this work, we employ a number of deep learning models with different architectures, and we train them on non-anomalous, randomly generated data sequences. The models are then used to predict/reconstruct the   


(i) a CNN-based Autoencoder



- Introduction
- Deep Learning Algorithms
Check: Unsupervised Anomaly Detection in Energy Time Series Data using
Variational Recurrent Autoencoders with Attention 
  - CNN-based Autoencoders
  - LSTM-based Autoencoders
  - CNNs
  - RNNs (LSTM)
  - Transformer

- Training Data Sets and Data Flow + Inspiration
- Results:
- Summary 
- References 
